#!/bin/bash
#
# collector my script for reconnaissance during
# my job as pentester or as a hobby doing bug bounty
#

collector_command_line="$0 $@"

banner(){
# Always print the banner
echo -e "                                 __ __             __
                    ____ ____   / // /___   ____ _/ /_ ____   ____
                   / __// __ \ / // // _ \ / __//_ __// __ \ / __/ 
                  / /__/ /_/ // // // ___// /__ / /_ / /_/ // /  
                  \___/\____//_//_/ \___/ \___/ \__/ \____//_/   

                                                 by skate_forever
"
}

collector_path=$(dirname $0)

if [ -s "${collector_path}/collector.cfg" ]; then
    source "${collector_path}/collector.cfg"
else
    echo -e "Please ${red}make sure${reset} you have the ${yellow}collector.cfg${reset} file."
    echo -e "${yellow}You need this to set the tools parameters${reset}!"
    echo -e "You will set aquatone, gobuster and dirsearch threads, docker network for privoxy instances and others."
    exit 1
fi

# Verifying if all binaries there are in the system
count=0
for binary in aquatone amass diff dig dirsearch dnssearch docker git-dumper \
   gobuster host jq massdns nmap nuclei subfinder waybackurls whois; do
   if ! command -v "${binary}" > /dev/null 2>&1 ; then
      echo -e "The ${red}${binary} does not exist${reset} on the system!"
      ((count += 1))
   fi
done

if [ "${count}" -gt 0 ]; then
    echo -e "Please, ${yellow}make sure${reset} you got all tools (binaries and scripts)."
    echo -e "You could use the ${yellow}get-tools.sh${reset} to get all binaries and scripts!"
    #echo -e "Or you could use the collector script ${yellow}inside docker${reset} with Dockerfile in collector-docker directory."
    unset count
    exit 1
fi

if [ -n "${shodan_use}" ]; then
    shodan_use=$(echo "${shodan_use}" | tr A-Z a-z)
    if [ "${shodan_use}" == "yes" ]; then
        [[ -n "${shodan_just_scan_main_domain}" ]] && \
            shodan_just_scan_main_domain=$(echo "${shodan_just_scan_main_domain}" | tr A-Z a-z)
        shodan_bin=$(command -v shodan)
        if [ -n "${shodan_bin}" ] ; then
            if [ -n "${shodan_apikey}" ] && [ ! -s ~/.shodan/api_key ]; then
                "${shodan_bin}" init "${shodan_apikey}" > /dev/null
            fi
        else
            echo -e "${red}You trying to use Shodan but you didn't install the shodan binary!${reset}"
            echo "Please, execute the command below to install: "
            echo "\tpip3 install shodan"
            exit 1
        fi
    fi
fi

# Script usage description
usage(){
    (
    echo -e "Basic usage:"
    echo -e "       ${yellow}$0${reset} ${green}-d domain.com -ws -wt curl${reset}"
    echo -e "       ${yellow}$0${reset} ${green}-dl /path/file/domain_list.txt -ws -wt curl${reset}"
    echo -e "       ${yellow}$0${reset} ${green}-u http://domain.com${reset}\n"
    echo "Options: "
    echo -e "\t-d |--domain              - Specify a valid domain [${red}needed${reset}]."
    echo -e "\t-dl|--domain-list         - Specify a valid domain [${red}needed${reset}]."
    echo -e "\t-e |--exclude-domains     - Specify excluded subdomains after all treated files [${red}used only with -d|--domain${reset}]:"
    echo -e "\t\t\t\t    ${yellow}use -e domain1.com,domain2.com or --exclude-domains domain1.com,domain2.com${reset}"
    echo -e "\t-k |--kill                - Will kill the current execution of collector, you need to specify the domain as argument."
    echo -e "\t-ka|--kill-all            - Will kill the current execution of collector and delete the directory of results from current execution, you need to specify the domain as argument."
    echo -e "\t-l |--limit-urls          - Specify the url quantity to run dirsearch and gobuster for dirs and files enumeration [${red}used only with -d|--domain${reset}]:"
    echo -e "\t\t\t\t    ${yellow}use -l 10 or --limit-urls 10${reset}"
    echo -e "\t-o |--output              - This option when specified will use the directory to save the output of collector script if omitted the default value is:"
    echo -e "\t\t\t\t    ${yellow}${PWD}${reset}"
    echo -e "\t\t\t\t  - This option as well as others can be configured on collector.cfg, variable output_dir or use the parameters like:"
    echo -e "\t\t\t\t ${yellow}   use -o /path/of/output or --output-dir /path/of/output${reset}"
    echo -e "\t-p |--proxy               - This option when specified will use privoxy instance using docker trying to avoid or bypass WAF block:"
    echo -e "\t\t\t\t    ${yellow}use -p or --proxy${reset}"
    echo -e "\t-r |--resolver            - specify the DNS to resolve, default value is 8.8.8.8 used only with ${red}-d|--domain${reset}:"
    echo -e "\t\t\t\t    ${yellow}use -r 1.1.1.1 or --resolver 1.1.1.1,8.8.8.8${reset}"
    echo -e "\t-re|--recon               - Will execute a recon until you find out what domains are webpage: ${red}used only with -d|--domain${reset} WITHOUT ${red}-wd|--web-data${reset}."
    echo -e "\t-s |--subdomain-brute     - Specify the wordlist to put in dns_wordlist array and execute gobuster and dnssearch brute force [${red}used only with -d|--domain${reset}]"
    echo -e "\t\t\t\t    by default the array is empty and not execute amass, gobuster and dnssearch. This option take a long time to finish, use this own your need!"
    echo -e "\t\t\t\t  - The success of use those tools is a good wordlist:"
    echo -e "\t\t\t\t    ${yellow}use -s /path/to/wordlist1,/path/to/wordlist2 or --subdomain-brute /path/to/wordlist1,/path/to/wordlist2${reset}"
    echo -e "\t-u |--url                 - Specify a valid url [${red}needed${reset}]."
    echo -e "\t-wd|--web-data            - Will execute a web data dig after execution of collector with recon option (${red}-re|--recon${reset}): used only with ${red}-d|--domain${reset} WITHOUT ${red}-re|--recon${reset}."
    echo -e "\t-wl|--web-long-detection  - Will execute the long list of ports setup in collector.cfg as variable web_port_long_detection." 
    echo -e "\t-ws|--web-short-detection - Will execute the short list of ports setup in collector.cfg as variable web_port_short_detection."
    echo -e "\t-wt|--web-tool-detection  - You need to inform what tool to perform web application detection the tool can be ${bold}${yellow}curl${reset}${normal} OR ${bold}${yellow}httpx${reset}${normal}."
    echo -e "\t-ww|--web-wordlists       - Specity more wordlists to put in web_wordlist array, by default we use the $(echo ${web_tools_dir} | sed "s/\/home\/.*\/pentest/~\/pentest/")/dirsearch/db/dicc.txt"
    echo -e "\t\t\t\t    as the first wordlist to enumerate dirs and files from website."
    echo -e "\t\t\t\t    ${yellow}use -w /path/to/wordlist1,/path/to/wordlist2 or --web-wordlists /path/to/wordlist1,/path/to/wordlist2${reset}"
    ) 1>&2; exit 1
}

check_argument(){
    options+=(-d --domain -dl --domain-list -e --exclude-domains -k -kill -ka --kill-all -l --limit-urls -o --output -p --proxy -r --resolver -re --recon)
    options+=(-s --subdomain-brute -u --url -wd --web-data -wl --web-long-detection -ws --web-short-detection -wt --web-tool-detection -ww --web-wordlists)
    if [[ "${options[@]}" =~ "$2" ]]; then
            echo -e "The argument of ${yellow}\"$1\"${reset} it can not be ${red}\"$2\"${reset}, please, ${yellow}specify a valid one${reset}.\n"
            usage
    fi
}

kill_collector(){
    for pid in $(ps aux | grep "${1::1}${1:1}" | awk '{print $2}'); do
        kill -9 "${pid}" > /dev/null 2>&1
    done
    exit 0
}

args_count=0
only_recon="no"
only_web_data="no"

while [ $# -ne 0 ]; do
    (( args_count += 1 ))
    case $1 in
        -d|--domain)
            check_argument $1 $2
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use \"-d|--domain\" or \"-u|--url\", never both together!\n"
                usage
            elif [[ -s "${domain_list}" ]]; then
                banner
                echo -e "You can only use \"-d|--domain\" or \"-dl|--domain-list\", never both together!\n"
                usage
            else
                if [[ $(timeout 5s host -W 3 -t A "$2" > /dev/null 2>&1; echo $?) -eq 0 ]]; then
                    domain="$2"
                    unset directories_structure
                    directories_structure="domain"
                    shift 2
                else
                    banner
                    echo -e "You need specify a valid domain!\n"
                    usage
                fi
            fi
            ;;
        -dl|--domain-list)
            check_argument $1 $2
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use \"-dl|--domain-list\" or \"-u|--url\", never both together!\n"
                usage
            elif [[ -s "${domain_list}" ]]; then
                banner
                echo -e "You can only use \"-dl|--domain-list\" or \"-d|--domain\", never both together!\n"
                usage
            else
                if [ -s $2 ]; then
                    domain_list=$2
                    unset directories_structure
                    directories_structure="domain"
                    shift 2
                else
                    banner
                    echo -e "Please provide a valid file with domains.\n"
                    usage
                fi
            fi
            ;;
        -e|--exclude-domains)
            check_argument $1 $2
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use this (-e|--exlude-domains) option with \"-d|--domain\"!\n"
                usage
            fi
            set -f
            IFS=","
            excluded+=($2)
	        unset IFS
            shift 2
            ;;
        -k|--kill)
            check_argument $1 $2
            if [ -z $2 ]; then
                banner
                echo "You need to specify a domain to kill the execution!"
                exit 1
            else
                kill_collector $2
            fi
            ;;
        -kr|--kill-remove)
            check_argument $1 $2
            if [ -z $2 ]; then
                banner
                echo "You need to specify a domain to kill the execution!"
                exit 1
            else
                kill_collector $2
                rm -rf $(find / -iname "$(find / -iname $2 -type d -exec ls -1 {} \; 2>/dev/null | grep recon_ | tail -n1)" -type d 2> /dev/null)
            fi
            ;;
        -l|--limit-urls)
            check_argument $1 $2
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use this (-l|--limit-urls) option with \"-d|--domain\"!\n"
                usage
            fi
            if [[ -n $2 && $2 == ?(-)+([0-9]) ]]; then
                limit_urls="$2"
                shift 2
            else
                banner
                echo -e "Specify the total number of URLs you want to test!\n"
                usage
            fi
            ;;
        -o|--output)
            check_argument $1 $2
            [ ! -d "$2" ] && mkdir -p "$2" 2> /dev/null
            if [[ $(cd $2 > /dev/null 2>&1 ; echo "$?") -eq 0 ]] && [[ $(touch $2/permission_to_write.txt > /dev/null 2>&1; echo "$?") -eq 0 ]]; then
                unset output_dir
                output_dir="$(echo $2 | sed -e 's/\/$//')"
                shift 2
                rm -rf "${output_dir}/permission_to_write.txt"
            else
                banner
                echo -e "Please, you need to specify a ${yellow}valid directory you own or have access permission${reset}!\n"
                usage
            fi
            ;;
        -p|--proxy)
            use_proxy=yes
            shift
            ;;
        -r|--resolver)
            check_argument $1 $2
            if [[ -n $2 && $2 =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                set -f
                IFS=","
                #for dns_argument in $(echo $2 | sed "s/,/\n/"); do
                    [[ ! "${dns_servers[@]}" =~ "${dns_argument}" ]] && dns_servers+="${dns_argument}"
                #done
                unset IFS
                shift 2
            else
                banner
                echo -e "Please specify one address IP to use to resolve names!\n"
                usage
            fi
            ;;
        -re|--recon)
            if [[ -n "${only_web_data}" ]] && [[ "${only_web_data}" == "yes"  ]]; then
                banner
                echo -e "You can't use this (-re|--recon) option with \"-wd|--web-data\"!\n"
                usage
            fi
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "With this option (-re|--recon) You can only use \"-d|--domain\"!\n"
                usage
            fi
            only_recon=yes
            shift
            ;;
        -s|--subdomain-brute)
            check_argument $1 $2
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "You can only use this (-s|--subdomain-brute) option with \"-d|--domain\"!\n"
                usage
            fi
            set -f
            IFS=","
            dns_wordlists+=($2)
            unset IFS
            shift 2
            ;;
        -u|--url)
            check_argument $1 $2
            if [[ -n "${domain}" ]]; then
                banner
                echo -e "You can only use \"-u|--url\" or \"-d|--domain\", never both together!\n"
                usage
            elif [[ -s "${domain_list}" ]]; then
                banner
                echo -e "You can only use \"-u|--url\" or \"-dl|--domain-list\", never both together!\n"
                usage
            else
                [[ -n "$2" ]] && status_code=$(curl -o /dev/null -s -w "%{http_code}" "$2")
                if [[ -z ${status_code} || "${status_code}" -eq "000" ]];then
                    banner
                    echo -e "You need specify a valid URL!\n"
                    usage
                else
                    url_2_verify=$2
                    unset directories_structure
                    directories_structure="url"
                    shift 2
                fi
            fi
            unset status_code
            ;;
        -wd|--web-data)
            if [[ -n "${only_recon}" ]] && [[ "${only_recon}" == "yes"  ]]; then
                banner
                echo -e "You can't use this (-wd|--web-data) option with \"-re|--recon\"!\n"
                usage
            fi
            if [[ -n "${url_2_verify}" ]]; then
                banner
                echo -e "With this option (-wd|--web-data) You can only use \"-d|--domain\"!\n"
                usage
            fi
            only_web_data=yes
            shift
            ;;
        -ws|--web-short-detection)
            if [ "${#web_port_detect[@]}" -eq 0 ]; then
                web_port_detect=("${web_port_short_detection[@]}")
            else
                diff_array=$(diff <(printf "%s\n" "${web_port_detect[@]}") <(printf "%s\n" "${web_port_short_detection[@]}"))
                if [[ "${#web_port_detect[@]}" -ne 0 ]] && [[ -n ${diff_array} ]]; then
                    banner
                    echo -e "You need to specify just sort or long web port detection, not both!\n"
                    unset web_port_detect
                    usage
                fi
            fi
            shift
            ;;
        -wt|--web-tool-detection)
            check_argument $1 $2
            if [[ "curl" != "$2" && "httpx" != "$2" ]] ; then
                banner
                echo -e "You need to inform one of these tools curl or httpx!\n"
                usage
            else
                unset web_tool_detection
                web_tool_detection="$2"
                if [ "${web_tool_detection}" == "httpx" ]; then
                    if ! command -v httpx > /dev/null 2>&1 ; then
                        banner
                        echo -e "The ${red}httpx does not exist${reset} on the system!"
                        echo -e "Please install the httpx and put in your PATH!"
                        exit 1
                    fi
                fi
                shift 2
            fi
            ;;
        -wl|--web-long-detection)
            if [ "${#web_port_detect[@]}" -eq 0 ]; then
                web_port_detect=("${web_port_long_detection[@]}")
            else
                diff_array=$(diff <(printf "%s\n" "${web_port_detect[@]}") <(printf "%s\n" "${web_port_long_detection[@]}"))
                if [[ "${#web_port_detect[@]}" -ne 0 ]] && [[ -n ${diff_array} ]]; then
                    banner
                    echo -e "You need to specify just sort or long web port detection, not both!\n"
                    unset web_port_detect
                    usage
                fi
            fi
            shift
            ;;
        -ww|--web-wordlists)
            check_argument $1 $2
            set -f
            IFS=","
            web_wordlists+=($2)
            unset IFS
            shift 2
            ;;
        -?*)
            usage
            ;;
        *)
            break
    esac
done

# Checking if the script has the main parameters needed
if [[ -z "${url_2_verify}" ]] && [[ -z "${domain}" ]] && [[ ! -s "${domain_list}" ]]; then
    banner
    echo -e "You need at least one option \"-u|--url\", \"-d|--domain\" OR \"-dl|--domain-list\" to execute this script!\n"
    usage
fi

# Verify the if exist the default resolvers list
if [ ! -s "${dns_resolvers_file}" ]; then
    banner
    echo "The resolvers file does not exist, please fix it, downloading from this source: "
    echo "\thttps://public-dns.info/nameservers.txt"
    echo " "
    echo -e "After the download put the path to nameservers.txt file in dns_resolvers_file variable in collector.cfg file.\n"
    usage
fi

# Verify the if exist the default wordlist for web
if [ ${#web_wordlists[@]} -eq 0 ]; then
    banner
    echo -e "Please, ${yellow}make sure${reset} you have the default wordlists to web directory and file discovery!\n"
    usage
fi

# Create the structure
create_initial_directories_structure(){

    if [ "${directories_structure}" == "domain" ]; then
        # Create all dirs necessaries to report and recon for domain
        mkdir -p "${output_dir}/${domain}"/{log,"recon_domain_${date_recon}"}
        log_dir="${output_dir}/${domain}/log"
        log_file="${log_dir}/recon_domain_${date_recon}.log"
        log_error_file="${log_dir}/recon_domain_error_${date_recon}.log"
        recon_dir="${output_dir}/${domain}/recon_domain_${date_recon}"
        # secundaries directories
        mkdir -p "${recon_dir}"/{aquatone-data,nuclei-data,report,tmp,wayback-data,web-data}
        aquatone_files_dir="${recon_dir}/aquatone-data"
        nuclei_dir="${recon_dir}/nuclei-data"
        report_dir="${recon_dir}/report"
        shodan_dir="${recon_dir}/shodan-data"
        if [[ "${shodan_use}" == "yes" ]] && [[ ! -d "${shodan_dir}" ]]; then
            mkdir -p "${shodan_dir}"
        fi
        tmp_dir="${recon_dir}/tmp"
        wayback_dir="${recon_dir}/wayback-data"
        web_data_dir="${recon_dir}/web-data"
    fi

    if [ "${directories_structure}" == "url" ]; then
        # Create all dirs necessaries to report and recon for url
        mkdir -p "${output_dir}"/"${url_domain}"/{log,"recon_url_${date_recon}"}
        log_dir="${output_dir}/${url_domain}/log"
        log_file="${log_dir}/recon_url_${date_recon}.log"
        recon_dir="${output_dir}/${url_domain}/recon_url_${date_recon}"
    
        # secundaries directories
        mkdir -p "${recon_dir}/${url_base}"/{report,aquatone-data}
        report_dir="${recon_dir}/${url_base}/report"
        aquatone_files_dir="${recon_dir}/${url_base}/aquatone-data"
        nuclei_dir="${report_dir}"
        shodan_dir="${report_dir}"
        tmp_dir="${report_dir}"
        web_data_dir="${report_dir}"
        wayback_dir="${report_dir}"
    fi

}

# Checking if the essencial functions there are
for file in detects_webpage diff git recon scans web_data; do
    function="${collector_path}/functions/${file}.sh"
    if [ -s "${function}" ]; then
        source "${function}"
    else
        banner
        echo -e "Please ${red}make sure${reset} you have the ${yellow}"${function}"${reset} file."
        echo -e "${yellow}You need this file to execute collector${reset}!"
        exit 1
    fi
done

# Checking if is a know target to get the cursor position
check_is_known_target(){
    if [[ -n "$1" ]] && [[ -d "${output_dir}/$1" ]]; then
        echo "This is a known target."
        cursor_start_position=30
    else
        cursor_start_position=29
    fi
}

message(){
    target="$1"
    echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} ${green}Recon finished on${reset} ${yellow}${target}${reset}${green}!${reset}"
    echo -e "\t ${green}Consider to use recon-ng and theHarvester to help get more assets!${reset}"
    echo -e "\t ${green}Use Shoda.io, Censys and others.${reset}"
    unset target
}

domain_execution(){

    echo "Directory structure created and ready to work." | tee -a "${log_file}"

    (# Show the directory structure
    echo "The directory structure you will have to work with, is..."
    echo " "
    echo "${output_dir}/${domain}"
    echo -e " ├── log (${yellow}log dir for collector script execution${reset})"
    echo -e " └── $(basename "${recon_dir}")"
    echo -e "     ├── aquatone-data (${yellow}aquatone output files${reset})"
    echo -e "     ├── nuclei-data (${yellow}nuclei execution output files${reset})"
    echo -e "     ├── report (${yellow}adjust function output files${reset})"
    echo -e "     ├── tmp (${yellow}subdomains recon tmp files${reset})"
    echo -e "     ├── wayback-data (${yellow}web data function for waybackurl output${reset})"
    echo -e "     └── web-data (${yellow}web data function for gobuster and dirsearch output${reset})"
    echo " "
    echo -e "${red}Attention:${reset} The output from all tools used here will be placed in background and treated later."
    echo -e "\t   If you need look the output in execution time, you need to \"tail\" the files."
    echo " "
    # Execute all functions
    echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} ${green}Recon started on${reset} ${yellow}${domain}${reset}${green}!${reset}"
    if [ "${only_web_data}" == "no" ]; then
        subdomains_recon
        adjust_files
        hdc
        diff_domains
        nmap_ips
        shodan_scan
        webapp_alive
    fi
    if [ "${only_recon}" == "yes" ]; then
        message "${domain}"
        exit 1
    fi
    if [ "${only_web_data}" == "yes" ] && [ ! -s "${report_dir}/domains_web.txt" ]; then
        echo "You haven't the actual domains_web.txt file to collect data to analyze!"
        echo "Please, run the collector with -d domain --recon or just -d domain to run recon and web data!"
        exit 1
    fi
    web_data "${report_dir}/domains_web.txt"
    cleanup_web_data_files
    robots_txt
    web_data "${report_dir}/robots_urls.txt"
    cleanup_web_data_files
    for file in "${report_dir}/domains_web.txt" "${report_dir}/robots_urls.txt" ; do
        aquatone_function "${file}"
    done
    rebuild_git
    #report
    message) 2>&1 | tee -a "${log_file}"
}

url_exection(){
    echo "Directory structure created and ready to work." | tee -a "${log_file}"

    (# Show the directory structure
    echo "The directory structure you will have to work with, is..."
    echo " "
    echo "${output_dir}/${url_domain}"
    echo -e " ├── log (${yellow}log dir for collector script execution${reset})"
    echo -e " └── $(basename "${recon_dir}")"
    echo -e "     └── ${url_base} (${yellow}specific directory for the files referring to the tested url${reset})" 
    echo -e "         ├── aquatone-data (${yellow}aquatone output files${reset})"
    echo -e "         └── report (${yellow}adjust function output files${reset})"
    echo " "
    echo -e "${red}Attention:${reset} The output from all tools used here will be placed in background and treated later."
    echo -e "\t   If you need look the output in execution time, you need to \"tail\" the files."
    echo " "
    # Executing just the functions necessary to url check
    echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} ${green}Recon started on${reset} ${yellow}${url_base}${reset}${green}!${reset}"
    web_data "${recon_dir}/url_2_test.txt"
    cleanup_web_data_files
    robots_txt
    web_data "${report_dir}/robots_urls.txt"
    cleanup_web_data_files
    for file in "${recon_dir}/url_2_test.txt" "${report_dir}/robots_urls.txt" ; do
        aquatone_function "${file}"
    done
    rebuild_git 
    message "${url_2_verify}"
    rm "${recon_dir}/url_2_test.txt" > /dev/null 2>&1) 2>&1 | tee -a "${log_file}"
}

# Checking the runtime parameter dependency for domain recon
check_parameter_dependency_domain(){
    [[ "${args_count}" -gt 9 ]] && echo -e "You are trying to pass a number of parameters beyond what is necessary for this collector reconnaissance option \"${yellow}-d|--domain${reset}\".\n" && usage

    if [ "${#dns_servers[*]}" -eq 0 ]; then
        echo "You need to inform at least ONE DNS Server that realy works properly!"
        echo -e "You can add editing the collector.cfg or use the ${yellow}-r|--resolve${reset} option to append the DNS in dns_servers array (no comma between servers)!\n"
        usage
    fi

    if [[ ${#web_port_detect[@]} -eq 0 ]]; then
        echo -e "You need to specify at least one of these options sort (-ws|--web-short-detection) or long (-wl|--web-long-detection) web detection!\n"
        usage
    fi

    if [[ -z "${web_tool_detection}" ]]; then
        echo -e "You need to inform one of these tools ${bold}${yellow}curl${reset}${normal} or ${bold}${yellow}httpx${reset}${normal} to perform web application detection.\n"
        usage
    fi
}

if [[ -n ${domain} ]] && [[ ! -s "${domain_list}" ]] && [[ -z "${url_2_verify}" ]]; then
    clear >$(tty)
    echo -e "${collector_command_line}\n"
    banner
    check_parameter_dependency_domain
    check_is_known_target "${domain}"
    create_initial_directories_structure
    domain_execution
fi

if [[ -z ${domain} ]] && [[ -s "${domain_list}" ]] && [[ -z "${url_2_verify}" ]]; then
    unset domain
    for domain in $(cat "${domain_list}"); do
        clear >$(tty)
        echo -e "${collector_command_line}\n"
        banner
        check_parameter_dependency_domain
        check_is_known_target "${domain}"
        create_initial_directories_structure
        if [[ $(timeout 5s host -W 3 -t A "${domain}" > /dev/null 2>&1; echo $?) -eq 0 ]]; then
            domain_execution
        else
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} The ${yellow}${domain}${reset} does not exist!" | tee -a "${report_dir}/domain_doesnot_exit.txt"
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} ${green}Recon finished on${reset} ${yellow}${domain}${reset}${green}!${reset}"
        fi
        unset domain
    done
fi

if [[ -z ${domain} ]] && [[ ! -s "${domain_list}" ]] && [[ -n "${url_2_verify}" ]]; then
    # Checking the runtime parameter dependency for url recon
    if [[ -n "${url_2_verify}" && -n "${domain}" ]] || [[ -n "${dns_wordlists}" && -n "${dns_servers[0]}" ]] || \
        [[ -n "${url_2_verify}" && -n "${limit_urls}" ]] || [[ -n "${url_2_verify}" && -n "${excluded}" ]]; then
        echo -e "You have specified one or more options that are not used with \"-u|--url\"!\n"
        usage
    fi

    if [[ "${args_count}" -gt 4 ]]; then
         echo -e "You are trying to pass a number of parameters beyond what is necessary for this collector reconnaissance option \"${yellow}-u|--url${reset}\".\n"
         usage
    fi
    url_base=$(echo "${url_2_verify}" | sed -e 's/http.*\/\///' | awk -F'/' '{print $1}' | xargs -I {} basename {})
    mapfile -d'.' -t url_tmp_domain <<< "${url_base}"
    for (( i=$((${#url_tmp_domain[@]}-1)); i>=0; i-- ));do
        url_domain=$(echo "${url_tmp_domain[$i]}.${url_domain}" | sed -e 's/\.$//' -e 's/^\.//' -e 's/[[:space:]]*$//')
        [[ $(timeout 5s host -W 3 -t A "${url_domain}" | grep -v "Host.*not.found:" | awk '{print $4}' | \
            grep -E "^^([0-9]+(\.|$)){4}|^([0-9a-fA-F]{0,4}:){1,7}([0-9a-fA-F]){0,4}$") ]] && break
    done

    [[ -s "${recon_dir}/url_2_test.txt"  ]] && rm "${recon_dir}/url_2_test.txt"

    if [[ $(echo "${url_2_verify}" | grep -qE "^(http|https)://" ; echo "$?") -eq 0 ]]; then
        echo "${url_2_verify}" > "${recon_dir}/url_2_test.txt"
    else
        [[ "200" -eq "$(curl -o /dev/null -s -w "%{http_code}\n" "http://${url_2_verify}")" ]] && echo "http://${url_2_verify}" > "${recon_dir}/url_2_test.txt"
        [[ "200" -eq "$(curl -o /dev/null -s -w "%{http_code}\n" "https://${url_2_verify}")" ]] && echo "https://${url_2_verify}" > "${recon_dir}/url_2_test.txt"
    fi

    clear >$(tty)
    echo -e "$0 $@\n"
    banner
    check_is_known_target "${url_domain}"
    create_initial_directories_structure
    url_execution
fi
